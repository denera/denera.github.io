[{"authors":["admin"],"categories":null,"content":"Passionate computational scientist specializing on large‐scale gradient‐based optimization algorithms and their applications in scientific discovery, engineering design, artificial intelligence and machine learning problems. Extensive experience developing high‐quality scientific software on heterogeneous high‐performance computing systems, with significant contributions to large open source projects.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"http://alp.dener.me/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Passionate computational scientist specializing on large‐scale gradient‐based optimization algorithms and their applications in scientific discovery, engineering design, artificial intelligence and machine learning problems. Extensive experience developing high‐quality scientific software on heterogeneous high‐performance computing systems, with significant contributions to large open source projects.","tags":null,"title":"","type":"authors"},{"authors":["Shinhoo Kang","Alp Dener","Aidan Hamilton","Emil M. Constantinescu","Robert L. Jacob"],"categories":[],"content":"","date":1645660800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645660800,"objectID":"7e23a796d8351d7168aa50aa8ce569d0","permalink":"http://alp.dener.me/publication/multiratens/","publishdate":"2020-02-19T13:29:56-06:00","relpermalink":"/publication/multiratens/","section":"publication","summary":"Earth system models are complex integrated models of atmosphere, ocean, sea ice, and land surface. Coupling the components can be a significant challenge due to the difference in physics, temporal, and spatial scales. This study explores new coupling strategies for the fluid-fluid interaction problem based on multirate partitioned Runge-Kutta methods. We consider compressible Navier-Stokes equations with gravity coupled through a rigid-lid interface. Our large-scale numerical experiments reveal that multirate partitioned Runge-Kutta coupling schemes (1) can conserve total mass; (2) have second-order accuracy in time; and (3) provide favorable strong- and weak-scaling performance on modern computing architectures. We also show that the speedup factors of multirate partitioned Runge-Kutta methods match theoretical expectations over their base (single-rate) method. ","tags":[],"title":"Multirate partitioned Runge–Kutta methods for coupled Navier–Stokes equations (submitted)","type":"publication"},{"authors":["Richard Tran Mills","Mark F. Adams","Satish Balay","Jed Brown","Alp Dener","Matthew Knepley","Scott E. Kruger","Hannah Morgan","Todd Munson","Karl Rupp","Barry F. Smith","Stefano Zampini","Hong Zhang","Junchao Zhang"],"categories":[],"content":"","date":1604275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604275200,"objectID":"83e740dfe740e638a12366b45e815929","permalink":"http://alp.dener.me/publication/petscgpu/","publishdate":"2020-02-19T13:29:56-06:00","relpermalink":"/publication/petscgpu/","section":"publication","summary":"The Portable Extensible Toolkit for Scientific computation (PETSc) library delivers scalable solvers for nonlinear time-dependent differential and algebraic equations and for numerical optimization.The PETSc design for performance portability addresses fundamental GPU accelerator challenges and stresses flexibility and extensibility by separating the programming model used by the application from that used by the library, and it enables application developers to use their preferred programming model, such as Kokkos, RAJA, SYCL, HIP, CUDA, or OpenCL, on upcoming exascale systems. A blueprint for using GPUs from PETSc-based codes is provided, and case studies emphasize the flexibility and high performance achieved on current GPU-based systems. ","tags":[],"title":"Toward Performance-Portable PETSc for GPU-based Exascale Systems","type":"publication"},{"authors":["M. Andres Miller","R. Michael Churchill","Alp Dener","Choong-Seock Chang","Todd S. Munson","Robert Hager"],"categories":[],"content":"","date":1600041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600041600,"objectID":"940678b1ed4f777e6ee1f70daaede024","permalink":"http://alp.dener.me/publication/xgcml/","publishdate":"2020-02-19T13:29:56-06:00","relpermalink":"/publication/xgcml/","section":"publication","summary":"An encoder-decoder neural network has been used to examine the possibility for acceleration of a partial integro-differential equation, the Fokker-Planck-Landau collision operator. This is part of the governing equation in the massively parallel particle-in-cell code, XGC, which is used to study turbulence in fusion energy devices. The neural network emphasizes physics-inspired learning, where it is taught to respect physical conservation constraints of the collision operator by including them in the training loss, along with the L2 loss. In particular, network architectures used for the computer vision task of semantic segmentation have been used for training. A penalization method is used to enforce the 'soft' constraints of the system and integrate error in the conservation properties into the loss function. During training, quantities representing the density, momentum, and energy for all species of the system is calculated at each configuration vertex, mirroring the procedure in XGC. This simple training has produced a median relative loss, across configuration space, on the order of 10E-04, which is low enough if the error is of random nature, but not if it is of drift nature in timesteps. The run time for the Picard iterative solver of the operator scales as order n squared, where n is the number of plasma species. As the XGC1 code begins to attack problems including a larger number of species, the collision operator will become expensive computationally, making the neural network solver even more important, since the training only scales as n. A wide enough range of collisionality is considered in the training data to ensure the full domain of collision physics is captured. An advanced technique to decrease the losses further will be discussed, which will be subject of a subsequent report. Eventual work will include expansion of the network to include multiple plasma species. ","tags":[],"title":"Encoder-decoder neural network for solving the nonlinear Fokker-Planck-Landau collision operator in XGC","type":"publication"},{"authors":["Alp Dener","Adam Denchfield","Todd S. Munson"],"categories":[],"content":"","date":1560297600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560297600,"objectID":"561571a45eba9e3431a0df10dab33164","permalink":"http://alp.dener.me/publication/cgprecond/","publishdate":"2020-02-19T13:36:14-06:00","relpermalink":"/publication/cgprecond/","section":"publication","summary":"Nonlinear conjugate gradient (NCG) methods can generate search directions using only first-order information and a few dot products, making them attractive algorithms for solving large-scale optimization problems. However, even the most modern NCG methods can require large numbers of iterations and, therefore, many function evaluations to converge to a solution. This poses a challenge for simulation-constrained problems where the function evaluation entails expensive partial or ordinary differential equation solutions. Preconditioning can accelerate convergence and help compute a solution in fewer function evaluations. However, general-purpose preconditioners for nonlinear problems are challenging to construct. In this paper, we review a selection of classical and modern NCG methods, introduce their preconditioned variants, and propose a preconditioner based on the diagonalization of the BFGS formula. As with the NCG methods, this preconditioner utilizes only first-order information and requires only a small number of dot products. Our numerical experiments using CUTEst problems indicate that the proposed preconditioner successfully reduces the number of function evaluations at negligible additional cost for its update and application.","tags":[],"title":"Preconditioning Nonlinear Conjugate Gradient with Diagonalized Quasi-Newton","type":"publication"},{"authors":["Alp Dener","Todd S. Munson"],"categories":[],"content":"","date":1559952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559952000,"objectID":"e7c917c0564652a6732f5369bc942a10","permalink":"http://alp.dener.me/publication/qnaccel/","publishdate":"2020-02-19T13:32:38-06:00","relpermalink":"/publication/qnaccel/","section":"publication","summary":"Quasi-Newton methods are popular gradient-based optimization methods that can achieve rapid convergence using only first-order derivatives. However, the choice of the initial Hessian matrix upon which quasi-Newton updates are applied is an important factor that can significantly affect the performance of the method. This fact is especially true for limited-memory variants, which are widely used for large-scale problems where only a small number of updates are applied in order to minimize the memory footprint. In this paper, we introduce both a scalar and a sparse diagonal Hessian initialization framework, and we investigate its effect on the restricted Broyden-class of quasi-Newton methods. Our implementation in PETSc/TAO allows us to switch between different Broyden class methods and Hessian initializations at runtime, enabling us to quickly perform parameter studies and identify the best choices. The results indicate that a sparse Hessian initialization based on the diagonalization of the BFGS formula significantly improves the base BFGS methods and that other parameter combinations in the Broyden class may offer competitive performance.","tags":[],"title":"Accelerating Limited-Memory Quasi-Newton Convergence for Large-Scale Optimization","type":"publication"},{"authors":["Alp Dener","Jason E. Hicken","Gaetan K. W. Kenway","Joaquim R. R. A. Martins"],"categories":[],"content":"","date":1532649600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532649600,"objectID":"a3beec287446c3dcd11a9bd96068ef9f","permalink":"http://alp.dener.me/publication/aerostruct/","publishdate":"2020-02-19T13:29:56-06:00","relpermalink":"/publication/aerostruct/","section":"publication","summary":"The individual discipline feasible (IDF) formulation is a modular multidisciplinary design optimization architecture that promotes the use of disparate discipline analysis tools. IDF achieves modularity by introducing coupling variables and coupling constraints into the optimization problem, which enables the state equations for each discipline to be solved independently at each optimization iteration. However, the increased number of optimization variables and nonlinear state-based constraints poses a significant challenge to conventional matrix-explicit optimization algorithms. In this paper, we apply a reduced-space inexact-Newton-Krylov (RSNK) algorithm to a large-scale, high-fidelity aerostructural optimization of a commercial airliner wing. Our findings demonstrate that the RSNK algorithm, paired with a novel matrix-free preconditioner, can solve the IDF problem at least as fast as its multidisciplinary feasible counterpart. In particular, the IDF preconditioner remains highly effective even in the presence of thousands of coupling constraints. ","tags":[],"title":"Enabling Modular Aerostructural Optimization: Individual Discipline Feasible without the Jacobians","type":"publication"},{"authors":["Alp Dener"],"categories":[],"content":"","date":1511049600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511049600,"objectID":"0f40cf545adf79432be77d9037b7794b","permalink":"http://alp.dener.me/publication/thesis/","publishdate":"2020-02-19T13:10:41-06:00","relpermalink":"/publication/thesis/","section":"publication","summary":"The individual discipline feasible (IDF) formulation is a multidisciplinary design optimization (MDO) architecture that provides modularity for the underlying discipline solvers. Similar to reduced-space methods, the IDF formulation does not require the optimization algorithm to converge the state variables for each disci- pline in addition to the optimization variables; the state equations are still solved fully at each optimization iteration. However, IDF decouples the discipline equations from each other through the introduction of coupling variables and constraints to the optimization problem. Consequently, the discipline solutions at each optimization iteration can be performed independently and in parallel. This promotes the use of existing discipline-specific PDE solvers, and lowers the software development challenge of creating efficient coupled discipline analyses.\nDespite its advantages in modularity, the IDF architecture has remained largely unused by researchers and practitioners alike since its introduction in the early 1990s. The addition of large numbers of variables and constraints into the optimization problem proved to be challenging for conventional gradient-based optimization approaches. In particular, the explicit constraint Jacobian required by these algorithms is prohibitively expensive to compute for IDF problems.\nIn this thesis, we propose a reduced-space inexact-Newton-Krylov (RSNK) algorithm that can address the challenges posed by the IDF formulation. RSNK achieves this with three key components: a matrix-free formulation that avoids explicit Jacobians and Hessians, a new Krylov solver tailored for nonconvex saddle-point problems, and a novel matrix-free preconditioner for the IDF architecture. We implement RSNK in a parallel-agnostic optimization library, and verify its efficacy on a range of low- and high-fidelity test problems drawn from aerospace applications. Our findings demonstrate that RSNK scales favorably with the size of the design space, exhibits superlinear asymptotic convergence, and can efficiently solve large-scale PDE-governed MDO problems.","tags":[],"title":"A Modular Matrix-Free Approach to Multidisciplinary Design Optimization","type":"publication"},{"authors":["Jason E. Hicken","Pengfei Meng","Alp Dener"],"categories":[],"content":"","date":1505865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505865600,"objectID":"e4212a102af5b97e63fc4e13eaac16f0","permalink":"http://alp.dener.me/publication/multisecant/","publishdate":"2020-02-19T13:29:56-06:00","relpermalink":"/publication/multisecant/","section":"publication","summary":"We present a derivative-based algorithm for nonlinearly constrained optimization problems that is tolerant of inaccuracies in the data. The algorithm solves a semi-smooth set of nonlinear equations that are equivalent to the first-order optimality conditions, and it is matrix-free in the sense that it does not require the explicit Lagrangian Hessian or Jacobian of the constraints. The solution method is quasi-Newton, but rather than approximating only the Hessian or constraint Jacobian, the Jacobian of the entire nonlinear set of equations is approximated using a multisecant method. We show how preconditioning can be incorporated into the multisecant update in order to improve the performance of the method. For nonconvex problems, we propose a simple modification of the secant conditions to regularize the Hessian. Numerical experiments suggest that the algorithm is a promising alternative to conventional gradient-based algorithms, particularly when errors are present in the data. ","tags":[],"title":"Error-tolerant Multisecant Method for Nonlinearly Constrained Optimization","type":"publication"},{"authors":["Alp Dener","Jason E. Hicken"],"categories":[],"content":"","date":1498176000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498176000,"objectID":"d7d12225374769e6458fab95159621d2","permalink":"http://alp.dener.me/publication/matfree/","publishdate":"2020-02-19T13:06:59-06:00","relpermalink":"/publication/matfree/","section":"publication","summary":"Multidisciplinary engineering systems are usually modeled by coupling software components that were developed for each discipline independently. The use of disparate solvers complicates the optimization of multidisciplinary systems and has been a long-standing motivation for optimization architectures that support modularity. The individual discipline feasible (IDF) formulation is particularly attractive in this respect. IDF achieves modularity by introducing optimization variables and constraints that effectively decouple the disciplinary solvers during each optimization iteration. Unfortunately, the number of variables and constraints can be significant, and the IDF constraint Jacobian required by most conventional optimization algorithms is prohibitively expensive to compute. Furthermore, limited-memory quasi-Newton approximations, commonly used for large-scale problems, exhibit linear convergence rates that can struggle with the large number of design variables introduced by the IDF formulation. In this work, we show that these challenges can be overcome using a reduced-space inexact-Newton-Krylov algorithm. The proposed algorithm avoids the need for the explicit constraint Jacobian and Hessian by using a Krylov iterative method to solve the Newton steps. The Krylov method requires matrix-vector products, which can be evaluated in a matrix-free manner using second-order adjoints. The Krylov method also needs to be preconditioned, and a key contribution of this work is a novel and effective preconditioner that is based on approximating a monolithic solution of the (linearized) multidisciplinary system. We demonstrate the efficacy of the algorithm by comparing it with the popular multidisciplinary feasible formulation on two test problems.","tags":[],"title":"Matrix-free algorithm for the optimization of multidisciplinary systems","type":"publication"},{"authors":["Alp Dener","Pengfei Meng","Jason E. Hicken","Graeme J. Kennedy","John T. Hwang","Justin S. Gray"],"categories":[],"content":"","date":1452038400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1452038400,"objectID":"a62ff8e4f01eb5df7f5b9f1498bd3c30","permalink":"http://alp.dener.me/publication/kona/","publishdate":"2020-02-19T13:02:45-06:00","relpermalink":"/publication/kona/","section":"publication","summary":"Kona is a Python library targeting partial-differential-equation (PDE) governed optimization problems. To address the high computational cost of such problems, Kona permits parallel execution of linear algebra and optimization operations while remaining agnostic to the implementation details of the underlying PDE solver. To accomplish this, Kona adopts a reverse-communication-inspired interface where the optimization algorithm requests the PDE solver to perform a predetermined set of tasks on solver-generated memory. Consequently, the optimization itself is parallelized as long as the user defines parallel data structures within an abstract vector interface and performs the requested tasks in parallel. This abstraction layer also facilitates the rapid development of new optimization algorithms independently from the underlying PDE solvers. In this paper we describe Kona’s software design in detail, and demonstrate its use on test cases, ranging from analytical verification problems to a PDE-constrained engineering system.","tags":[],"title":"Kona: A Parallel Optimization Library for Engineering-Design Problems","type":"publication"},{"authors":["Jason E. Hicken","Alp Dener"],"categories":[],"content":"","date":1437436800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437436800,"objectID":"24852112076adf77ca41ba9fbd0ccc3e","permalink":"http://alp.dener.me/publication/flecs/","publishdate":"2020-02-19T12:58:03-06:00","relpermalink":"/publication/flecs/","section":"publication","summary":"We present an iterative primal-dual solver for nonconvex equality-constrained quadratic optimization subproblems. The solver constructs the primal and dual trial steps from the subspace generated by the generalized Arnoldi procedure used in flexible GMRES (FGMRES). This permits the use of a wide range of preconditioners for the primal-dual system. In contrast with FGMRES, the proposed method selects the subspace solution that minimizes a quadratic penalty function over a trust region. Analysis of the method indicates the potential for fast asymptotic convergence near the solution, which is corroborated by numerical experiments. The results also demonstrate the effectiveness and efficiency of the method in the presence of nonconvexity. Overall, the iterative solver is a promising matrix-free linear algebra kernel for inexact-Newton optimization algorithms and is well-suited to partial differential equation--constrained optimization.","tags":[],"title":"A Flexible Iterative Solver for Nonconvex, Equality-Constrained Quadratic Subproblems","type":"publication"},{"authors":["Alp Dener","Gaetan K. W. Kenway","Zhoujie Lyu","Jason E. Hicken","Joaquim R. R. A. Martins"],"categories":[],"content":"","date":1420761600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420761600,"objectID":"050b0ec8be7e55ef98c448fc7efa8cef","permalink":"http://alp.dener.me/publication/aso/","publishdate":"2020-02-19T12:54:56-06:00","relpermalink":"/publication/aso/","section":"publication","summary":"Large-scale aerodynamic and multidisciplinary design problems challenge conventional optimization algorithms, because these problems typically involve thousands of design variables and constraints. Alternative algorithms must be developed that produce solutions to large-scale design problems in a reasonable time. To this end, we investigate a scalable reduced-space Newton–Krylov optimization algorithm. This inexact-Newton algorithm uses a novel matrix-free Krylov solver that requires only KKT-matrix-vector products; these products are formed by solving two linear PDEs. We present preliminary results that benchmark the inexact-Newton algorithm against a conventional quasi-Newton algorithm on the Euler-based drag minimization of the Common-Research-Model wing benchmark. For this problem, the preliminary results indicate that the inexact-Newton algorithm scales well and outperforms the conventional algorithm for problems with more than 500 design variables.","tags":[],"title":"Comparison of inexact- and Quasi-Newton Algorithms for Aerodynamic Shape Optimization","type":"publication"},{"authors":["Alp Dener","Jason E. Hicken"],"categories":[],"content":"","date":1389830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1389830400,"objectID":"062422059ff43d93e298fa769a177216","permalink":"http://alp.dener.me/publication/idf/","publishdate":"2020-02-19T12:42:15-06:00","relpermalink":"/publication/idf/","section":"publication","summary":"The individual-discipline-feasible (IDF) formulation was proposed to simplify the implementation of MDO problems. The IDF formulation introduces coupling variables into the optimization problem that eliminate the need for a full multidisciplinary analysis at each optimization iteration; this simplifies the solution of MDO problems by maintaining modularity of the discipline software. Historically, the MDO community has used conventional optimization algorithms to solve IDF-formulated problems. Conventional optimizers are not well suited to IDF, because they use limited-memory quasi-Newton methods (linear convergence) and require the constraint Jacobian explicitly. The cost of computing the coupling-variable constraint Jacobian is prohibitively expensive for high-fidelity IDF problems. Matrix-free Reduced-Space inexact-Newton-Krylov (RSNK) algorithms overcome these issues, because they scale superlinearly and do not require the constraint Jacobian explicitly. Therefore, this class of algorithm has great potential to solve IDF-formulated MDO problems in a scalable and efficient manner. In this paper, we describe the application of RSNK to the IDF formulation and compare its performance to the multidisciplinary feasible architecture.","tags":[],"title":"Revisiting Individual Discipline Feasible using matrix-free Inexact-Newton-Krylov","type":"publication"}]